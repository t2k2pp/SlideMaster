// =================================================================
// AI Model Limits Configuration
// å„AIã‚µãƒ¼ãƒ“ã‚¹ãƒ»ãƒ¢ãƒ‡ãƒ«ã®åˆ¶é™å€¤ã‚’ä¸€å…ƒç®¡ç†
// =================================================================

export interface ModelLimits {
  maxInputTokens: number;
  maxOutputTokens: number;
  contextWindow: number;
  description: string;
  deprecated?: boolean;
  deprecationDate?: string;
}

export interface AIServiceLimits {
  [modelName: string]: ModelLimits;
}

export interface AllAIServiceLimits {
  gemini: AIServiceLimits;
  azureOpenAI: AIServiceLimits;
}

/**
 * å„AIã‚µãƒ¼ãƒ“ã‚¹ã®å®Ÿéš›ã®åˆ¶é™å€¤
 * å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦å®šæœŸçš„ã«æ›´æ–°
 */
export const AI_MODEL_LIMITS: AllAIServiceLimits = {
  // Google Gemini
  gemini: {
    'gemini-2.0-flash': {
      maxInputTokens: 1048576, // 1M tokens
      maxOutputTokens: 8192,
      contextWindow: 1048576,
      description: 'Gemini 2.0 Flash - æœ€æ–°é«˜é€Ÿãƒ¢ãƒ‡ãƒ«'
    },
    'gemini-1.5-pro': {
      maxInputTokens: 2097152, // 2M tokens
      maxOutputTokens: 8192,
      contextWindow: 2097152,
      description: 'Gemini 1.5 Pro - é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«'
    },
    'gemini-1.5-flash': {
      maxInputTokens: 1048576, // 1M tokens
      maxOutputTokens: 8192,
      contextWindow: 1048576,
      description: 'Gemini 1.5 Flash - é«˜é€Ÿãƒ¢ãƒ‡ãƒ«'
    }
  },

  // Azure OpenAI
  azureOpenAI: {
    // GPT-4o ã‚·ãƒªãƒ¼ã‚º
    'gpt-4o-2024-11-20': {
      maxInputTokens: 128000,
      maxOutputTokens: 16384,
      contextWindow: 128000,
      description: 'GPT-4o (2024-11-20) - æœ€æ–°ç‰ˆ'
    },
    'gpt-4o-2024-08-06': {
      maxInputTokens: 128000,
      maxOutputTokens: 16384,
      contextWindow: 128000,
      description: 'GPT-4o (2024-08-06)'
    },
    'gpt-4o-2024-05-13': {
      maxInputTokens: 128000,
      maxOutputTokens: 4096,
      contextWindow: 128000,
      description: 'GPT-4o (2024-05-13) - åˆæœŸç‰ˆ',
      deprecated: true,
      deprecationDate: '2025-01-31'
    },
    'gpt-4o-mini': {
      maxInputTokens: 128000,
      maxOutputTokens: 16384,
      contextWindow: 128000,
      description: 'GPT-4o Mini - è»½é‡ç‰ˆ'
    },

    // GPT-5 ã‚·ãƒªãƒ¼ã‚º (æ–°è¦è¿½åŠ )
    'gpt-5': {
      maxInputTokens: 200000,
      maxOutputTokens: 32768,
      contextWindow: 200000,
      description: 'GPT-5 - æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ« (è¿‘æ—¥æä¾›äºˆå®š)'
    },
    'gpt-5-turbo': {
      maxInputTokens: 200000,
      maxOutputTokens: 32768,
      contextWindow: 200000,
      description: 'GPT-5 Turbo - é«˜é€Ÿç‰ˆ (è¿‘æ—¥æä¾›äºˆå®š)'
    },

    // GPT-4 Turbo ã‚·ãƒªãƒ¼ã‚º
    'gpt-4-turbo-2024-04-09': {
      maxInputTokens: 128000,
      maxOutputTokens: 4096,
      contextWindow: 128000,
      description: 'GPT-4 Turbo (2024-04-09)'
    },
    'gpt-4-0125-preview': {
      maxInputTokens: 128000,
      maxOutputTokens: 4096,
      contextWindow: 128000,
      description: 'GPT-4 Turbo Preview'
    },

    // å¾“æ¥ã®GPT-4
    'gpt-4': {
      maxInputTokens: 8192,
      maxOutputTokens: 4096,
      contextWindow: 8192,
      description: 'GPT-4 - æ¨™æº–ç‰ˆ'
    },
    'gpt-4-32k': {
      maxInputTokens: 32768,
      maxOutputTokens: 4096,
      contextWindow: 32768,
      description: 'GPT-4 32K - é•·æ–‡å¯¾å¿œ'
    }
  }
};

/**
 * å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—
 * @param service AIã‚µãƒ¼ãƒ“ã‚¹å
 * @param model ãƒ¢ãƒ‡ãƒ«å
 * @param safetyMargin å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ (0.0-1.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.9)
 * @returns æ¨å¥¨æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
 */
export function getRecommendedMaxTokens(
  service: 'gemini' | 'azureOpenAI',
  model: string,
  safetyMargin: number = 0.9
): number {
  const modelLimits = AI_MODEL_LIMITS[service]?.[model];
  
  if (!modelLimits) {
    console.warn(`âš ï¸ Unknown model: ${service}/${model}. Using default fallback.`);
    return service === 'gemini' ? 7372 : 14745; // 90% of common limits
  }

  const recommendedMax = Math.floor(modelLimits.maxOutputTokens * safetyMargin);
  
  console.log(`ğŸ“Š Token limit for ${service}/${model}:`, {
    maxOutputTokens: modelLimits.maxOutputTokens,
    safetyMargin,
    recommendedMax
  });
  
  return recommendedMax;
}

/**
 * æŒ‡å®šã•ã‚ŒãŸAIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
 * @param service AIã‚µãƒ¼ãƒ“ã‚¹å
 * @param model ãƒ¢ãƒ‡ãƒ«å
 * @returns ãƒ¢ãƒ‡ãƒ«åˆ¶é™æƒ…å ±
 */
export function getModelLimits(
  service: 'gemini' | 'azureOpenAI',
  model: string
): ModelLimits | null {
  return AI_MODEL_LIMITS[service]?.[model] || null;
}

/**
 * éæ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®è­¦å‘Šè¡¨ç¤º
 * @param service AIã‚µãƒ¼ãƒ“ã‚¹å
 * @param model ãƒ¢ãƒ‡ãƒ«å
 */
export function checkModelDeprecation(
  service: 'gemini' | 'azureOpenAI',
  model: string
): void {
  const limits = getModelLimits(service, model);
  
  if (limits?.deprecated) {
    console.warn(`âš ï¸ Model ${service}/${model} is deprecated.`, {
      description: limits.description,
      deprecationDate: limits.deprecationDate,
      recommendation: 'Consider upgrading to a newer model'
    });
  }
}

/**
 * åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
 * @param service AIã‚µãƒ¼ãƒ“ã‚¹å
 * @param includeDeprecated éæ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚‚å«ã‚ã‚‹ã‹ã©ã†ã‹
 * @returns ãƒ¢ãƒ‡ãƒ«åã®é…åˆ—
 */
export function getAvailableModels(
  service: 'gemini' | 'azureOpenAI',
  includeDeprecated: boolean = true
): string[] {
  const serviceModels = AI_MODEL_LIMITS[service];
  
  if (!serviceModels) {
    return [];
  }

  return Object.entries(serviceModels)
    .filter(([_, limits]) => includeDeprecated || !limits.deprecated)
    .map(([modelName]) => modelName);
}

/**
 * ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
 * æœªçŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã«ä½¿ç”¨ã•ã‚Œã‚‹å®‰å…¨ãªå€¤
 */
export const DEFAULT_TOKEN_LIMITS = {
  gemini: {
    maxOutputTokens: 7372, // Geminiã®90%
    safeMargin: 0.9
  },
  azureOpenAI: {
    maxOutputTokens: 14745, // GPT-4oã®90%
    safeMargin: 0.9
  }
} as const;