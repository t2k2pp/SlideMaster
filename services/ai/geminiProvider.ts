// =================================================================
// Gemini Provider - 新プロバイダーシステム対応Gemini実装
// 既存コードをリファクタリングして新アーキテクチャに適合
// =================================================================

import { GoogleGenAI } from "@google/genai";
import { 
  AIProvider,
  AIProviderType,
  AIProviderConfig,
  TextGenerationRequest,
  ImageGenerationRequest,
  VideoAnalysisRequest,
  AIProviderError,
  AIProviderConnectionError,
  AIProviderConfigError
} from './aiProviderInterface';

import { ModelInfo, getAvailableModels } from './modelRegistry';

// 既存のGemini関連インポート
import { resolveAutoImageSettings } from '../utils/imageConsistency';
import { getTemperatureForTask } from '../geminiApiClient';

export class GeminiProvider implements AIProvider {
  name: AIProviderType = 'gemini';
  private client: GoogleGenAI;
  private config: AIProviderConfig;
  private fileManager: any = null;

  constructor(config: AIProviderConfig) {
    this.config = config;
    
    if (!config.apiKey) {
      throw new AIProviderConfigError(
        'Gemini API key is required',
        'gemini'
      );
    }

    try {
      this.client = new GoogleGenAI({ apiKey: config.apiKey });
    } catch (error) {
      throw new AIProviderConnectionError(
        `Failed to initialize Gemini client: ${error.message}`,
        'gemini',
        error as Error
      );
    }
  }

  async generateText(request: TextGenerationRequest): Promise<string> {
    try {
      const model = this.client.getGenerativeModel({ 
        model: request.model || this.config.models.textGeneration 
      });

      const prompt = request.systemPrompt 
        ? `${request.systemPrompt}\n\n${request.prompt}`
        : request.prompt;

      const result = await model.generateContent({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig: {
          temperature: request.temperature || 0.7,
          maxOutputTokens: request.maxTokens || 8192,
        },
      });

      const response = result.response;
      const text = response.text();
      
      if (!text) {
        throw new AIProviderError(
          'No text generated by Gemini',
          'gemini'
        );
      }

      return text;
    } catch (error) {
      throw this.handleGeminiError(error, 'Text Generation');
    }
  }

  async generateImage(request: ImageGenerationRequest): Promise<string> {
    try {
      const modelId = request.model || this.config.models.imageGeneration;
      
      // Gemini 2.0のネイティブ画像生成か、Imagen APIかを判定
      if (this.isGemini2Model(modelId)) {
        return await this.generateImageWithGemini2(request);
      } else {
        return await this.generateImageWithImagen(request);
      }
    } catch (error) {
      throw this.handleGeminiError(error, 'Image Generation');
    }
  }

  async analyzeVideo(request: VideoAnalysisRequest): Promise<string> {
    try {
      const model = this.client.getGenerativeModel({ 
        model: request.model || this.config.models.videoAnalysis 
      });

      const result = await model.generateContent({
        contents: [{
          role: 'user',
          parts: [
            { text: request.prompt },
            {
              inlineData: {
                mimeType: 'video/mp4',
                data: request.videoData.split(',')[1] // Remove data:video/mp4;base64, prefix
              }
            }
          ]
        }],
      });

      const response = result.response;
      const text = response.text();
      
      if (!text) {
        throw new AIProviderError(
          'No analysis generated by Gemini',
          'gemini'
        );
      }

      return text;
    } catch (error) {
      throw this.handleGeminiError(error, 'Video Analysis');
    }
  }

  async validateConfig(config: AIProviderConfig): Promise<boolean> {
    try {
      if (!config.apiKey) {
        return false;
      }

      // Simple API key validation by making a lightweight request
      const testClient = new GoogleGenAI({ apiKey: config.apiKey });
      const model = testClient.getGenerativeModel({ model: 'gemini-2.5-flash-lite' });
      
      await model.generateContent({
        contents: [{ role: 'user', parts: [{ text: 'test' }] }],
        generationConfig: { maxOutputTokens: 1 }
      });

      return true;
    } catch (error) {
      return false;
    }
  }

  async getAvailableModels(): Promise<{ [key: string]: string[] }> {
    try {
      const textModels = getAvailableModels('gemini', 'text').map(m => m.id);
      const imageModels = getAvailableModels('gemini', 'image').map(m => m.id);
      const videoModels = getAvailableModels('gemini', 'video').map(m => m.id);

      return {
        textGeneration: textModels,
        imageGeneration: imageModels,
        videoAnalysis: videoModels,
      };
    } catch (error) {
      return {
        textGeneration: [],
        imageGeneration: [],
        videoAnalysis: [],
      };
    }
  }

  async estimateCost(request: any): Promise<number> {
    // Gemini pricing calculation (simplified)
    const pricing = {
      'gemini-2.5-pro': { input: 1.25, output: 10.0 },
      'gemini-2.5-flash': { input: 0.075, output: 0.30 },
      'gemini-2.5-flash-lite': { input: 0.10, output: 0.40 },
      'gemini-2.0-flash': { input: 0.10, output: 0.40 },
      'imagen-4': { image: 0.08 },
      'imagen-3': { image: 0.04 },
    };

    const modelId = request.model || 'gemini-2.5-flash';
    const modelPricing = pricing[modelId];
    
    if (!modelPricing) {
      return 0.01; // Default small cost
    }

    if (request.task === 'text') {
      const inputTokens = Math.ceil((request.prompt?.length || 100) / 4);
      const outputTokens = request.maxTokens || 1000;
      return (inputTokens * modelPricing.input + outputTokens * modelPricing.output) / 1000000;
    } else if (request.task === 'image') {
      return modelPricing.image || 0.05;
    }

    return 0.01;
  }

  // Gemini 2.0ネイティブ画像生成
  private async generateImageWithGemini2(request: ImageGenerationRequest): Promise<string> {
    const model = this.client.getGenerativeModel({ model: request.model });

    const result = await model.generateContent({
      contents: [{
        role: 'user',
        parts: [{ text: `Generate an image: ${request.prompt}` }]
      }],
    });

    const response = result.response;
    if (response && response.candidates) {
      const candidate = response.candidates[0];
      if (candidate.content && candidate.content.parts) {
        for (const part of candidate.content.parts) {
          if (part.inlineData && part.inlineData.data) {
            const mimeType = part.inlineData.mimeType || 'image/jpeg';
            return `data:${mimeType};base64,${part.inlineData.data}`;
          }
        }
      }
    }

    throw new AIProviderError(
      'No image was generated by Gemini 2.0',
      'gemini'
    );
  }

  // Imagen API画像生成
  private async generateImageWithImagen(request: ImageGenerationRequest): Promise<string> {
    // Note: This is a simplified implementation
    // In a real implementation, you would use the Imagen API
    const config = {
      numberOfImages: request.n || 1,
      outputMimeType: 'image/jpeg',
      aspectRatio: '16:9',
    };

    if (request.seed !== undefined) {
      config.seed = request.seed;
    }

    // This would be the actual Imagen API call
    // For now, we'll throw an error indicating it needs proper implementation
    throw new AIProviderError(
      'Imagen API integration needs proper implementation',
      'gemini'
    );
  }

  // Gemini 2.0モデル判定
  private isGemini2Model(modelId: string): boolean {
    return modelId.startsWith('gemini-2.0');
  }

  // エラーハンドリング
  private handleGeminiError(error: unknown, context: string): AIProviderError {
    if (error instanceof AIProviderError) {
      return error;
    }

    if (error instanceof Error) {
      if (error.message.includes('API_KEY_INVALID')) {
        return new AIProviderConfigError(
          'Invalid Gemini API key. Please check your configuration.',
          'gemini',
          error
        );
      }
      if (error.message.includes('QUOTA_EXCEEDED')) {
        return new AIProviderError(
          'Gemini API quota exceeded. Please check your usage limits.',
          'gemini',
          'QUOTA_EXCEEDED',
          error
        );
      }
      if (error.message.includes('RATE_LIMIT_EXCEEDED')) {
        return new AIProviderError(
          'Gemini API rate limit exceeded. Please try again later.',
          'gemini',
          'RATE_LIMIT_EXCEEDED',
          error
        );
      }
      
      return new AIProviderError(
        `Gemini ${context} error: ${error.message}`,
        'gemini',
        'UNKNOWN_ERROR',
        error
      );
    }

    return new AIProviderError(
      `Gemini ${context}: Unknown error occurred`,
      'gemini',
      'UNKNOWN_ERROR'
    );
  }
}